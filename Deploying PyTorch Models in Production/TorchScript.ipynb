{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TorchScript\n",
    "    # 跟踪现有模块\n",
    "    # 使用脚本直接编译模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4a321ccf50>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch  # This is all you need to use both PyTorch and TorchScript!\n",
    "print(torch.__version__)\n",
    "torch.manual_seed(191009)  # set the seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.2541,  0.2460,  0.2297,  0.1014],\n",
      "        [-0.2329, -0.2911,  0.5641,  0.5015],\n",
      "        [ 0.1688,  0.2252,  0.7251,  0.2530]], grad_fn=<TanhBackward0>), tensor([[-0.2541,  0.2460,  0.2297,  0.1014],\n",
      "        [-0.2329, -0.2911,  0.5641,  0.5015],\n",
      "        [ 0.1688,  0.2252,  0.7251,  0.2530]], grad_fn=<TanhBackward0>))\n",
      "MyCell1(\n",
      "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "(tensor([[-0.2541,  0.2460,  0.2297,  0.1014],\n",
      "        [-0.2329, -0.2911,  0.5641,  0.5015],\n",
      "        [ 0.1688,  0.2252,  0.7251,  0.2530]], grad_fn=<TanhBackward0>), tensor([[-0.2541,  0.2460,  0.2297,  0.1014],\n",
      "        [-0.2329, -0.2911,  0.5641,  0.5015],\n",
      "        [ 0.1688,  0.2252,  0.7251,  0.2530]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "class MyCell1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell1, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.linear(x) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell1()\n",
    "x = torch.rand(3, 4)\n",
    "h = torch.rand(3, 4)\n",
    "print(my_cell(x, h))\n",
    "print(my_cell)\n",
    "print(my_cell(x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell2(\n",
      "  (dg): MyDecisionGate()\n",
      "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "(tensor([[ 0.5558, -0.5318, -0.4891,  0.4558],\n",
      "        [ 0.5980, -0.0933, -0.4871,  0.8160],\n",
      "        [ 0.6492, -0.2173,  0.0336,  0.7995]], grad_fn=<TanhBackward0>), tensor([[ 0.5558, -0.5318, -0.4891,  0.4558],\n",
      "        [ 0.5980, -0.0933, -0.4871,  0.8160],\n",
      "        [ 0.6492, -0.2173,  0.0336,  0.7995]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x[0][0] > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "class MyCell2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell2, self).__init__()\n",
    "        self.dg = MyDecisionGate()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell2()\n",
    "print(my_cell)\n",
    "print(my_cell(x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell1(\n",
      "  original_name=MyCell1\n",
      "  (linear): Linear(original_name=Linear)\n",
      ")\n",
      "<class 'torch.jit._trace.TopLevelTracedModule'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1917, 0.5628, 0.7345, 0.0488],\n",
       "         [0.5713, 0.5418, 0.4596, 0.3537],\n",
       "         [0.4559, 0.6762, 0.5744, 0.6472]], grad_fn=<TanhBackward0>),\n",
       " tensor([[0.1917, 0.5628, 0.7345, 0.0488],\n",
       "         [0.5713, 0.5418, 0.4596, 0.3537],\n",
       "         [0.4559, 0.6762, 0.5744, 0.6472]], grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cell = MyCell1()\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "# 给定输入示例，调用了Module，记录了运行时发生的操作Module，并创建了一个实例torch.jit.ScriptModule（其中TracedModule是实例）\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "print(traced_cell)\n",
    "print(type(traced_cell))\n",
    "traced_cell(x, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.1 : __torch__.___torch_mangle_16.MyCell,\n",
      "      %x : Float(3, 4, strides=[4, 1], requires_grad=0, device=cuda:0),\n",
      "      %h : Float(3, 4, strides=[4, 1], requires_grad=0, device=cuda:0)):\n",
      "  %linear : __torch__.torch.nn.modules.linear.___torch_mangle_15.Linear = prim::GetAttr[name=\"linear\"](%self.1)\n",
      "  %20 : Tensor = prim::CallMethod[name=\"forward\"](%linear, %x)\n",
      "  %11 : int = prim::Constant[value=1]() # /tmp/ipykernel_68168/2516425700.py:7:0\n",
      "  %12 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = aten::add(%20, %h, %11) # /tmp/ipykernel_68168/2516425700.py:7:0\n",
      "  %13 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = aten::tanh(%12) # /tmp/ipykernel_68168/2516425700.py:7:0\n",
      "  %14 : (Float(3, 4, strides=[4, 1], requires_grad=1, device=cuda:0), Float(3, 4, strides=[4, 1], requires_grad=1, device=cuda:0)) = prim::TupleConstruct(%13, %13)\n",
      "  return (%14)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_cell.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  linear = self.linear\n",
      "  _0 = torch.tanh(torch.add((linear).forward(x, ), h))\n",
      "  return (_0, _0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell1(\n",
      "  original_name=MyCell1\n",
      "  (linear): Linear(original_name=Linear)\n",
      ")\n",
      "<class 'torch.jit._trace.TopLevelTracedModule'>\n",
      "graph(%self.1 : __torch__.___torch_mangle_23.MyCell1,\n",
      "      %x : Float(3, 4, strides=[4, 1], requires_grad=0, device=cuda:0),\n",
      "      %h : Float(3, 4, strides=[4, 1], requires_grad=0, device=cuda:0)):\n",
      "  %linear : __torch__.torch.nn.modules.linear.___torch_mangle_22.Linear = prim::GetAttr[name=\"linear\"](%self.1)\n",
      "  %20 : Tensor = prim::CallMethod[name=\"forward\"](%linear, %x)\n",
      "  %11 : int = prim::Constant[value=1]() # /tmp/ipykernel_68168/3666525625.py:7:0\n",
      "  %12 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = aten::add(%20, %h, %11) # /tmp/ipykernel_68168/3666525625.py:7:0\n",
      "  %13 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = aten::tanh(%12) # /tmp/ipykernel_68168/3666525625.py:7:0\n",
      "  %14 : (Float(3, 4, strides=[4, 1], requires_grad=1, device=cuda:0), Float(3, 4, strides=[4, 1], requires_grad=1, device=cuda:0)) = prim::TupleConstruct(%13, %13)\n",
      "  return (%14)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 放在cuda上也可以\n",
    "my_cell = MyCell1().to(\"cuda\")\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "# 给定输入示例，调用了Module，记录了运行时发生的操作Module，并创建了一个实例torch.jit.ScriptModule（其中TracedModule是实例）\n",
    "traced_cell = torch.jit.trace(my_cell, (x.cuda(), h.cuda()))\n",
    "print(traced_cell)\n",
    "print(type(traced_cell))\n",
    "traced_cell(x.cuda(), h.cuda())\n",
    "print(traced_cell.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell2(\n",
      "  original_name=MyCell2\n",
      "  (dg): MyDecisionGate(original_name=MyDecisionGate)\n",
      "  (linear): Linear(original_name=Linear)\n",
      ")\n",
      "<class 'torch.jit._trace.TopLevelTracedModule'>\n",
      "graph(%self.1 : __torch__.___torch_mangle_361.MyCell2,\n",
      "      %x.1 : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu),\n",
      "      %h : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)):\n",
      "  %dg : __torch__.___torch_mangle_359.MyDecisionGate = prim::GetAttr[name=\"dg\"](%self.1)\n",
      "  %linear : __torch__.torch.nn.modules.linear.___torch_mangle_360.Linear = prim::GetAttr[name=\"linear\"](%self.1)\n",
      "  %35 : Tensor = prim::CallMethod[name=\"forward\"](%linear, %x.1)\n",
      "  %36 : NoneType = prim::CallMethod[name=\"forward\"](%dg, %35)\n",
      "  %22 : int = prim::Constant[value=1]() # /tmp/ipykernel_68168/274459315.py:15:0\n",
      "  %23 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::add(%35, %h, %22) # /tmp/ipykernel_68168/274459315.py:15:0\n",
      "  %24 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::tanh(%23) # /tmp/ipykernel_68168/274459315.py:15:0\n",
      "  %25 : (Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu), Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu)) = prim::TupleConstruct(%24, %24)\n",
      "  return (%25)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_68168/274459315.py:3: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x[0][0] > 0:\n"
     ]
    }
   ],
   "source": [
    "# 如果模型中包含控制流\n",
    "my_cell = MyCell2()\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "# 给定输入示例，调用了Module，记录了运行时发生的操作Module，并创建了一个实例torch.jit.ScriptModule（其中TracedModule是实例）\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "print(traced_cell)\n",
    "print(type(traced_cell))\n",
    "traced_cell(x, h)\n",
    "print(traced_cell.graph)\n",
    "# 查看.code输出，我们可以看到分支if-else无处可寻！为什么？跟踪正是按照我们所说的那样：运行代码，记录发生的操作并构造一个 ScriptModule执行该操作的程序。不幸的是，控制流之类的东西被抹去了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2479,  0.6963,  0.7758, -0.1620],\n",
       "         [ 0.5923,  0.4877,  0.8393,  0.2807],\n",
       "         [ 0.1735,  0.4953,  0.6595, -0.4612]], grad_fn=<TanhBackward0>),\n",
       " tensor([[ 0.2479,  0.6963,  0.7758, -0.1620],\n",
       "         [ 0.5923,  0.4877,  0.8393,  0.2807],\n",
       "         [ 0.1735,  0.4953,  0.6595, -0.4612]], grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_cell(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  if bool(torch.gt(torch.sum(x), 0)):\n",
      "    _0 = x\n",
      "  else:\n",
      "    _0 = torch.neg(x)\n",
      "  return _0\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  new_h = torch.tanh(_0)\n",
      "  return (new_h, new_h)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 我们提供了一个 脚本编译器，它直接分析你的 Python 源代码并将其转换为 TorchScript\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self, dg):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.dg = dg\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h\n",
    "    \n",
    "scripted_gate = torch.jit.script(MyDecisionGate())\n",
    "my_cell = MyCell(scripted_gate)\n",
    "scripted_cell = torch.jit.script(my_cell)\n",
    "\n",
    "print(scripted_gate.code)\n",
    "print(scripted_cell.code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.4915,  0.0575,  0.4354,  0.5988],\n",
      "        [ 0.8869,  0.2138,  0.1995,  0.7857],\n",
      "        [ 0.4822, -0.1772,  0.0927,  0.1350]],\n",
      "       grad_fn=<DifferentiableGraphBackward>), tensor([[ 0.4915,  0.0575,  0.4354,  0.5988],\n",
      "        [ 0.8869,  0.2138,  0.1995,  0.7857],\n",
      "        [ 0.4822, -0.1772,  0.0927,  0.1350]],\n",
      "       grad_fn=<DifferentiableGraphBackward>))\n"
     ]
    }
   ],
   "source": [
    "# x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "print(scripted_cell(x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell2(\n",
      "  (dg): MyDecisionGate()\n",
      "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(my_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.5907,  0.0780,  0.4297, -0.4303],\n",
      "        [ 0.6976, -0.5335,  0.4454,  0.0253],\n",
      "        [ 0.4735,  0.0993,  0.7769,  0.1649]],\n",
      "       grad_fn=<DifferentiableGraphBackward>), tensor([[ 0.5907,  0.0780,  0.4297, -0.4303],\n",
      "        [ 0.6976, -0.5335,  0.4454,  0.0253],\n",
      "        [ 0.4735,  0.0993,  0.7769,  0.1649]],\n",
      "       grad_fn=<DifferentiableGraphBackward>))\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  new_h = torch.tanh(_0)\n",
      "  return (new_h, new_h)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_cell = MyCell2()\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "scripted_cell = torch.jit.script(my_cell)\n",
    "scripted_cell2 = torch.jit.trace(my_cell,(x,h))\n",
    "print(scripted_cell(x,h))\n",
    "print(scripted_cell2(x,h)[0]==scripted_cell(x,h)[0])\n",
    "print(scripted_cell.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.5033)\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_68168/1645319762.py:6: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x.sum()>5:  # 控制流\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyCell3(nn.Module):\n",
    "    def forward(self, x, h):\n",
    "        if x[0][0] > 0:  # 控制流\n",
    "            return x + h\n",
    "        else:\n",
    "            return x - h\n",
    "\n",
    "my_cell = MyCell3()\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "print(x.sum())\n",
    "# 使用 script\n",
    "scripted_cell = torch.jit.script(my_cell)\n",
    "\n",
    "# 使用 trace\n",
    "scripted_cell2 = torch.jit.trace(my_cell, (x, h))\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "x[0][0]=1\n",
    "print(scripted_cell(x,h)==scripted_cell2(x,h))\n",
    "x[0][0]=-1\n",
    "print(scripted_cell(x,h)==scripted_cell2(x,h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=MyCell1\n",
      "  (linear): RecursiveScriptModule(original_name=Linear)\n",
      ")\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  linear = self.linear\n",
      "  _0 = torch.tanh(torch.add((linear).forward(x, ), h))\n",
      "  return (_0, _0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 模型的保存，顺便用于下一节的c++读入\n",
    "my_cell = MyCell1()\n",
    "x,h = torch.rand(3,4),torch.rand(3,4)\n",
    "traced_cell = torch.jit.trace(my_cell, (x,h))\n",
    "traced_cell.save('wrapped_rnn.pt')\n",
    "\n",
    "loaded = torch.jit.load('wrapped_rnn.pt')\n",
    "\n",
    "print(loaded)\n",
    "print(loaded.code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
