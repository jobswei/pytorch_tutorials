{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Here's a simple MLP\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "num_models = 10\n",
    "\n",
    "data = torch.randn(100, 64, 1, 28, 28, device=device)\n",
    "targets = torch.randint(10, (6400,), device=device)\n",
    "\n",
    "models = [SimpleMLP().to(device) for _ in range(num_models)]\n",
    "\n",
    "# 选项 1：每个模型使用不同的小批量\n",
    "minibatches = data[:num_models]\n",
    "predictions_diff_minibatch_loop = [model(minibatch) for model, minibatch in zip(models, minibatches)]\n",
    "# 选项 2：相同的小批量\n",
    "minibatch = data[0]\n",
    "predictions2 = [model(minibatch) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 10, 10, 10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "# 用于vmap矢量化集成\n",
    "\n",
    "# 首先，让我们通过堆叠每个参数将模型的状态组合在一起。例如，model[i].fc1.weight具有形状；我们将堆叠10 个模型中的每一个以产生形状为的大权重。[784, 128].fc1.weight[10, 784, 128]\n",
    "from torch.func import stack_module_state\n",
    "\n",
    "params, buffers = stack_module_state(models)\n",
    "\n",
    "from torch.func import functional_call\n",
    "import copy\n",
    "\n",
    "# Construct a \"stateless\" version of one of the models. It is \"stateless\" in\n",
    "# the sense that the parameters are meta Tensors and do not have storage.\n",
    "base_model = copy.deepcopy(models[0])\n",
    "base_model = base_model.to('meta')\n",
    "\n",
    "def fmodel(params, buffers, x):\n",
    "    return functional_call(base_model, (params, buffers), (x,))\n",
    "\n",
    "# 选项 1：使用每个模型的不同小批量来获取预测。\n",
    "print([p.size(0) for p in params.values()]) # show the leading 'num_models' dimension\n",
    "\n",
    "assert minibatches.shape == (num_models, 64, 1, 28, 28) # verify minibatch has leading dimension of size 'num_models'\n",
    "\n",
    "from torch import vmap\n",
    "\n",
    "predictions1_vmap = vmap(fmodel)(params, buffers, minibatches) # 默认in_dim=0, out_dim=0\n",
    "\n",
    "# verify the ``vmap`` predictions match the\n",
    "assert torch.allclose(predictions1_vmap, torch.stack(predictions_diff_minibatch_loop), atol=1e-3, rtol=1e-5)\n",
    "\n",
    "# 选项 2：使用相同的小批量数据获取预测。\n",
    "predictions2_vmap = vmap(fmodel, in_dims=(0, 0, None))(params, buffers, minibatch)\n",
    "\n",
    "assert torch.allclose(predictions2_vmap, torch.stack(predictions2), atol=1e-3, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions without vmap <torch.utils.benchmark.utils.common.Measurement object at 0x7f4aa24c6ad0>\n",
      "[model(minibatch) for model, minibatch in zip(models, minibatches)]\n",
      "  1.67 ms\n",
      "  1 measurement, 100 runs , 1 thread\n",
      "Predictions with vmap <torch.utils.benchmark.utils.common.Measurement object at 0x7f4a865d80d0>\n",
      "vmap(fmodel)(params, buffers, minibatches)\n",
      "  534.89 us\n",
      "  1 measurement, 100 runs , 1 thread\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.benchmark import Timer\n",
    "without_vmap = Timer(\n",
    "    stmt=\"[model(minibatch) for model, minibatch in zip(models, minibatches)]\",\n",
    "    globals=globals())\n",
    "with_vmap = Timer(\n",
    "    stmt=\"vmap(fmodel)(params, buffers, minibatches)\",\n",
    "    globals=globals())\n",
    "print(f'Predictions without vmap {without_vmap.timeit(100)}')\n",
    "print(f'Predictions with vmap {with_vmap.timeit(100)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
